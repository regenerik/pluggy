back:

-Node.js
-TypeScript
-web scrapping techniques, reverse engineering, just HTTP requests
-reload  cache faster than 60 sgs ( tal vez un loop )
-3 endpoints
-El slippage seria la diferencia con el promedio del mercado, por ejemplo si en promedio el dolar blue esta ~280 y una fuente tiene el precio en 282,8 el slippage de esa fuente seria +1% (puede ser negativo)

Back:
-puedo usar web scraping
-Reset valores cada 60 segundos ( sistema de cache que no muestre informacion mas vieja que 60 segundos )

-Deployado y funcionando, puedo usar heroku vercel o netlify
( ver como hacer que el back haga actualizacion de informacion cada menos de 60 segundos )


Front:

-Que muestre informacion de cada backend endpoint y que haga un refresh de la info
cada 15 segundos: setInterval(funcionQuePideAlBack() , 15000)
-React
-Redux ( y redux-saga ) INVESTIGAR
-vercel/netlify
-typescript
-Material UI

Design:

-Hace lo mejor que puedas

-------------------------------------------------------------------------------------

desde cero:

nodejs - axios - npm - cheerio - typescript - expressjs (revisar request-promise)

1 x front : npx create-react-app clients --template typescript
2 x Analizar la estructura y comparar con back de p.i/instalar express en back:
3 x Instalar axios en back nodemon: npm i -g nodemon /nodemon index.js
4 x Instalar cheerio en back
5 x Instalar typescript en back
6 - Instalar browserRouter en front
7 x Instalar Route en front
8 x Instalar Redux en front ( ver que es REDUX-SAGA )
9 x Una vez definida la estructura src/client ( ejemplo web scraping )
	-Crear un index.js que ejecute el servidor:
	const PORT = 8000
	const axios = require("axios")
	const cheerio = require("cheerio")
	const express = require("express")
	const app = express()
	
	const url = "la url aca"
	axios(`url`)
	.then(response => {
		const html = response.data
		const $ = cheerio.load(html)
		;

		$('.nombreClaseDeElemento', html).each(function()
			const title = $(this).text()
			const url = $(this).find('a').attr('href')
			articles.push({
				title,
				url
			});
		});
		console.log(articles)
	}).catch(err => console.log(err))
	

	

	app.listen(PORT, ()=> console.log(`server runing on Port ${PORT}`))
	
10 x rutas
-------------------------------------------------------------------------------
pedidos de las paginas : 

network  - https://mercados.ambito.com//dolar/informal/variacion

scraping - https://dolarhoy.com/cotizaciondolarblue   +  const valor = $('.value').text()

network - https://www.cronista.com/pieces/markets/id_draggable-1609816492000-835525__p_2/

-------------------------------------------------------------------------------
back vanilla terminado 30 / 08


-------------------------------------------------------------------------------
index inicia el servidor  en 3001 y ejecuta la funcion scraping que se encarga, 
desde el general controllers que se encuentra en src, de hacer el raspado" de informacion de las páginas indicadas.
Además de requerir el general controllers requiere tambien "app" de src que contiene 
toda la información pertinente a la activación del servidor para luego ejecutarlo


     "axios": "^0.27.2",              pedidos async html
     "body-parser": "^1.19.0",        permite tener acceso al objeto req
     "cheerio": "^1.0.0-rc.12",       scraping
     "cookie-parser": "^1.4.5",       analiza el encabezado Cookie y rellena req. cookies
     "cors": "^2.8.5",                Característica de seguridad del navegador que restringe las solicitudes HTTP 
     "dotenv": "^8.2.0",              variables de entorno (guardar las contraseñas o info de forma segura )
     "express": "^4.17.1",            framework de node proporciona mecanismos para peticios http en diferentes url
     "ioredis": "^4.19.2",            ???
     "jsonwebtoken": "^8.5.1",	      Para crear un token que sirva para enviar datos entre aplicaciones o servicios y garantizar que sean válidos y seguros
     "morgan": "^1.10.0",             iddleware de nivel de solicitud HTTP. Es una gran herramienta que registra las requests
     "pg": "^8.5.1",                  posgres db
     "sequelize": "^6.3.5"            db

------------------------------------------------------------------------------
Front TIMEEEE ! ! ! !

npm i react-router-dom
npm i Routes
npm i react-redux
npm i redux
npm i redux-thunk
npm i redux-devtools-extension

1 ) en index importar provider:                import { Provider } from "react-redux"
2 ) en index importar store:                   import  store  from "./redux/store"
3 ) en index como siempre envolver app en el:  <Provider store={store}></Provider>
4 ) en src crear carpeta redux conteniendo:
	actions.tsx
	reducer.tsx
	store.tsx
5 ) en app.js importar:     import { BrowserRouter, Route, Routes } from "react-router-dom";
6 ) importar las paginas:   import Landing from "./pages/Landing"
7 ) Rodear todo en return de:( 
			      <BrowserRouter>
				<Routes>
				  <Route path="/" element={<Landing />}/>
				</Routes>
			      </BrowserRouter>
			     )
8 ) en app no te olvides de : export default App; ( al final de la pag )









